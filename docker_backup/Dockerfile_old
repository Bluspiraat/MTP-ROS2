# FROM osrf/ros:jazzy-desktop-full

# # Install Python and essential tools
# RUN apt update && apt install -y \
#     python3-pip python3-setuptools python3-dev python3-venv python3-full\
#     build-essential cmake git wget curl unzip \
#     python3-colcon-common-extensions python3-rosdep \
#     && rm -rf /var/lib/apt/lists/*

# ENV CUDA_MAJOR_VERSION="11"
# ENV CUDA_VERSION="11.8"
# ENV CUDNN_VERSION="8.7.0.84-1"

# # 1. Install necessary dependencies (dpkg is for .deb packages)
# RUN apt update && apt install -y \
#     wget dpkg ca-certificates \
#     && rm -rf /var/lib/apt/lists/*

# # 2. DOWNLOAD AND INSTALL THE CUDA KEYRING PACKAGE
# # This step automatically installs the GPG key and adds the repository source.
# # We must use the Ubuntu 22.04 (jammy) file path.
# RUN wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb \
#     && dpkg -i cuda-keyring_1.1-1_all.deb \
#     && rm cuda-keyring_1.1-1_all.deb

# # FIX DEPENDENCY ISSUE: Manually install libtinfo5 for CUDA 11.x on Ubuntu 24.04.
# RUN apt update && apt install -y
# RUN wget http://security.ubuntu.com/ubuntu/pool/universe/n/ncurses/libtinfo5_6.3-2ubuntu0.1_amd64.deb \
# # RUN wget http://archive.ubuntu.com/ubuntu/pool/main/n/ncurses/libtinfo5_6.3-2ubuntu0.1_amd64.deb \
#     && dpkg -i libtinfo5_6.3-2ubuntu0.1_amd64.deb \
#     && rm libtinfo5_6.3-2ubuntu0.1_amd64.deb \
#     && apt-get install -f # Try to fix any broken dependencies after manual install

# # 3. Install specific cuDNN packages
# # The repository is now configured, so this step should finally work.
# RUN apt update && apt install -y --no-install-recommends \
#     cuda-toolkit-11-8 \
#     libcudnn8=${CUDNN_VERSION}+cuda${CUDA_VERSION} \
#     libcudnn8-dev=${CUDNN_VERSION}+cuda${CUDA_VERSION} \
#     && rm -rf /var/lib/apt/lists/*

# # 4. Add PATH and Symlinks (Crucial for ONNX Runtime to find the libraries)
# # You need to manually add these two RUN steps (or ENV variables) after the cuDNN install
# ENV PATH="/usr/local/cuda/bin:$PATH"
# ENV LD_LIBRARY_PATH="/usr/local/cuda/lib64:${LD_LIBRARY_PATH}"

# RUN ln -sf /usr/lib/x86_64-linux-gnu/libcudnn.so.8 /usr/local/cuda/lib64/libcudnn.so \
#     && ln -sf /usr/lib/x86_64-linux-gnu/libcudnn.so.8 /usr/local/cuda/lib64/libcudnn.so.8

# # Create a venv for Python packages
# RUN python3 -m venv /opt/pyenv

# # Initialize rosdep
# RUN rosdep init || true
# RUN rosdep update

# RUN /opt/pyenv/bin/pip install --upgrade pip

# # Install Python dependencies
# RUN /opt/pyenv/bin/pip install\
#     "numpy<2" \
#     opencv-python \
#     onnxruntime-gpu==1.18.0 \
#     timm \
#     --extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-11/pypi/simple/

# # Set workspace
# WORKDIR /ros2_ws

# # Make venv available in ROS environment
# ENV PATH="/opt/pyenv/bin:${PATH}"
# ENV PYTHONPATH="/opt/pyenv/lib/python3.12/site-packages:${PYTHONPATH}"

# SHELL ["/bin/bash", "-c"]
# RUN source /opt/ros/jazzy/setup.bash && \
#     python3 -m pip install --force-reinstall "numpy<2"

# ENTRYPOINT ["/bin/bash"]

# Use ROS Jazzy (Ubuntu 24.04) as the base image
FROM osrf/ros:jazzy-desktop-full

# Install Python and essential tools
RUN apt update && apt install -y \
    python3-pip python3-setuptools python3-dev python3-venv python3-full\
    build-essential cmake git wget curl unzip \
    python3-colcon-common-extensions python3-rosdep \
    && rm -rf /var/lib/apt/lists/*


# --- GPU/CUDA CONFIGURATION ---
# CRITICAL: We rely on the host's CUDA 13.1 libraries being injected via '--gpus all'.
# We set LD_LIBRARY_PATH to include both standard injection points for maximum visibility.
ENV LD_LIBRARY_PATH="/usr/local/nvidia/lib64:/usr/local/cuda/lib64:${LD_LIBRARY_PATH}"

# Create a venv for Python packages
RUN python3 -m venv /opt/pyenv

# Initialize rosdep
RUN rosdep init || true
RUN rosdep update

RUN /opt/pyenv/bin/pip install --upgrade pip

# Install Python dependencies
# We use a stable, CUDA 12-compatible version (1.18.1). This version should look
# for the .so.12 libraries, which the backward-compatible CUDA 13.0 host should provide.
RUN /opt/pyenv/bin/pip install\
    "numpy<2" \
    opencv-python \
    onnxruntime-gpu \
    timm

# Set workspace
WORKDIR /ros2_ws

# Make venv available in ROS environment
# Ensures ROS (colcon) and Python can find the Venv packages
ENV PATH="/opt/pyenv/bin:${PATH}"
ENV PYTHONPATH="/opt/pyenv/lib/python3.12/site-packages:${PYTHONPATH}"

# Setup environment for running ROS commands later
SHELL ["/bin/bash", "-c"]

# Reinstall numpy one last time in case it was installed by ROS dependencies
# and needs to be in the Venv path, or for dependency fixing
RUN source /opt/ros/jazzy/setup.bash && \
    python3 -m pip install --force-reinstall "numpy<2"

ENTRYPOINT ["/bin/bash"]